{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom tensorflow.keras.utils import to_categorical\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-08T00:06:40.901697Z","iopub.execute_input":"2022-07-08T00:06:40.902488Z","iopub.status.idle":"2022-07-08T00:06:50.78256Z","shell.execute_reply.started":"2022-07-08T00:06:40.902257Z","shell.execute_reply":"2022-07-08T00:06:50.781272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voice_lines = pd.read_csv(\"/kaggle/input/league-of-legends-voice-lines/voice_lines.csv\")\n\nvoice_lines.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T00:06:50.785314Z","iopub.execute_input":"2022-07-08T00:06:50.786204Z","iopub.status.idle":"2022-07-08T00:06:50.876178Z","shell.execute_reply.started":"2022-07-08T00:06:50.786143Z","shell.execute_reply":"2022-07-08T00:06:50.875242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voice_lines.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T00:06:50.877434Z","iopub.execute_input":"2022-07-08T00:06:50.877938Z","iopub.status.idle":"2022-07-08T00:06:50.935079Z","shell.execute_reply.started":"2022-07-08T00:06:50.877907Z","shell.execute_reply":"2022-07-08T00:06:50.933636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voice_lines.drop(voice_lines[voice_lines.is_spoken == False].index, inplace=True)\nvoice_lines.drop(['Unnamed: 0', 'is_spoken'], axis=1, inplace=True)\n\nvoice_lines.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T00:06:50.937422Z","iopub.execute_input":"2022-07-08T00:06:50.937921Z","iopub.status.idle":"2022-07-08T00:06:50.981479Z","shell.execute_reply.started":"2022-07-08T00:06:50.93789Z","shell.execute_reply":"2022-07-08T00:06:50.980527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_text = [\"this should be easy\", \"thats a mink if I've ever mink mink\", \"time to\"]\n\nvectorize_layer = keras.layers.TextVectorization(standardize=\"lower_and_strip_punctuation\",\n                                         split=\"whitespace\",\n                                         output_mode=\"int\")\n\nvectorize_layer.adapt(example_text)\n\nexample = vectorize_layer([\"mink be easy\", \"easy be mink\"])\nexample","metadata":{"execution":{"iopub.status.busy":"2022-07-08T00:06:50.98297Z","iopub.execute_input":"2022-07-08T00:06:50.983283Z","iopub.status.idle":"2022-07-08T00:06:51.42808Z","shell.execute_reply.started":"2022-07-08T00:06:50.983253Z","shell.execute_reply":"2022-07-08T00:06:51.427183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorize_layer.adapt(voice_lines[\"voice_line\"])\n\nvoice_lines_tokenized = []\n\nfor line in voice_lines[\"voice_line\"]:\n    token_list = vectorize_layer(line)\n    for i in range(1, len(token_list)):\n        n_gram_sequence = token_list[:i+1]\n        voice_lines_tokenized.append(n_gram_sequence.numpy().tolist())\ntotal_words = len(vectorize_layer.get_vocabulary())","metadata":{"execution":{"iopub.status.busy":"2022-07-08T00:06:51.429328Z","iopub.execute_input":"2022-07-08T00:06:51.429818Z","iopub.status.idle":"2022-07-08T00:09:01.084457Z","shell.execute_reply.started":"2022-07-08T00:06:51.429777Z","shell.execute_reply":"2022-07-08T00:09:01.083279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voice_lines_tokenized[0:10]","metadata":{"execution":{"iopub.status.busy":"2022-07-08T00:09:01.085907Z","iopub.execute_input":"2022-07-08T00:09:01.086242Z","iopub.status.idle":"2022-07-08T00:09:01.094976Z","shell.execute_reply.started":"2022-07-08T00:09:01.08621Z","shell.execute_reply":"2022-07-08T00:09:01.093601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\ndef generate_padded_sequences(input_sequences):\n    max_sequence_len = max([len(x) for x in input_sequences])\n    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n    \n    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n    label = to_categorical(label, num_classes=total_words)\n    return predictors, label, max_sequence_len\n\npredictors, label, max_sequence_len = generate_padded_sequences(voice_lines_tokenized)\n\npredictors","metadata":{"execution":{"iopub.status.busy":"2022-07-08T00:09:01.096538Z","iopub.execute_input":"2022-07-08T00:09:01.096857Z","iopub.status.idle":"2022-07-08T00:09:02.095394Z","shell.execute_reply.started":"2022-07-08T00:09:01.096809Z","shell.execute_reply":"2022-07-08T00:09:02.094402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(max_sequence_len, total_words):\n    input_len = max_sequence_len - 1\n    model = keras.Sequential()\n    \n    # Add Input Embedding Layer\n    model.add(keras.layers.Embedding(total_words, 10, input_length=input_len))\n    \n    # Add Hidden Layer 1 - LSTM Layer\n    model.add(keras.layers.LSTM(100))\n    model.add(keras.layers.Dropout(0.1))\n    \n    # Add Output Layer\n    model.add(keras.layers.Dense(total_words, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    \n    return model\n\nmodel = create_model(max_sequence_len, total_words)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T00:09:02.096831Z","iopub.execute_input":"2022-07-08T00:09:02.097419Z","iopub.status.idle":"2022-07-08T00:09:02.450664Z","shell.execute_reply.started":"2022-07-08T00:09:02.097386Z","shell.execute_reply":"2022-07-08T00:09:02.449386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(predictors, label, batch_size=3000, epochs=100, verbose=5)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T00:09:02.454932Z","iopub.execute_input":"2022-07-08T00:09:02.455264Z","iopub.status.idle":"2022-07-08T01:47:25.461012Z","shell.execute_reply.started":"2022-07-08T00:09:02.455234Z","shell.execute_reply":"2022-07-08T01:47:25.459948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel.save('/path_to_model/model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:48:03.308483Z","iopub.execute_input":"2022-07-08T01:48:03.308866Z","iopub.status.idle":"2022-07-08T01:48:03.371694Z","shell.execute_reply.started":"2022-07-08T01:48:03.308835Z","shell.execute_reply":"2022-07-08T01:48:03.370554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_text(seed_text, next_words, model, max_sequence_len):\n    for _ in range(next_words):\n        token_list = vectorize_layer(seed_text)\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n        prediction = model.predict(token_list)[0]\n                \n        partition = np.argpartition(prediction, -5)[-5:]\n        word_index = partition[np.random.choice(partition.shape[0], 1, replace=False)][0]\n        seed_text += \" \"+vectorize_layer.get_vocabulary()[word_index]\n        \n    return seed_text.title()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T04:30:39.912200Z","iopub.execute_input":"2022-07-08T04:30:39.912742Z","iopub.status.idle":"2022-07-08T04:30:39.945912Z","shell.execute_reply.started":"2022-07-08T04:30:39.912639Z","shell.execute_reply":"2022-07-08T04:30:39.944750Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"print (generate_text(\"world\", 15, model, max_sequence_len))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T04:30:51.235978Z","iopub.execute_input":"2022-07-08T04:30:51.236639Z","iopub.status.idle":"2022-07-08T04:30:51.251872Z","shell.execute_reply.started":"2022-07-08T04:30:51.236603Z","shell.execute_reply":"2022-07-08T04:30:51.250444Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/3244493844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"world\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sequence_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]}]}